# LLM Integration Configuration
# Controls LLM-based DSL program proposal generation

# LLM Model Configuration
model:
  name: "local/mock"           # placeholder, not loaded by default
  max_tokens: 128
  temperature: 0.2
  top_p: 0.9
  use_4bit_quantization: false
  gpu_memory_fraction: 0.5
  timeout_seconds: 5.0

# Proposal Generation
proposals:
  num_proposals: 2
  parsing_success_target: 0.5
  max_retries: 1
  fallback_enabled: true

# Prompt Configuration
prompts:
  template_type: "arc_standard"
  use_few_shot: false
  use_chain_of_thought: false
  max_examples: 0

# Training Data Configuration
training:
  synthetic_data_enabled: false
  num_synthetic_tasks: 0
  task_types: []
  difficulty_distribution:
    easy: 0.4
    medium: 0.4
    hard: 0.2
  
  # Soft-prompt tuning (if implemented)
  soft_prompt_length: 0
  tuning_epochs: 0
  learning_rate: 0.0
  batch_size: 0

# Integration with Search
search_integration:
  enabled: false
  beam_width_reduction: false
  original_beam_width: 64
  llm_beam_width: 8
  priority_boost: 1.0

  # Fallback configuration
  fallback_on_parsing_failure: true  # Fallback if parsing fails
  fallback_on_timeout: true  # Fallback on generation timeout
  fallback_on_model_error: true  # Fallback on model errors

# CLI Flag Mappings (mirror command-line interface options)
# These correspond to CLI flags like --llm, --llm-model, --llm-proposals
cli:
  llm_enabled: ${search_integration.enabled}  # Maps to --llm flag
  model_name: ${model.name}  # Maps to --llm-model flag
  num_proposals: ${proposals.num_proposals}  # Maps to --llm-proposals flag
  priority_boost: ${search_integration.priority_boost}  # Maps to --llm-priority-boost flag

# Performance Monitoring
monitoring:
  track_generation_time: false
  track_parsing_success: false
  track_proposal_quality: false
  log_failed_parses: false
  save_proposals: false

# Caching
caching:
  enabled: false
  cache_key_include_features: false
  cache_ttl: 0
  max_cache_size: 0

# Development and Debugging
debug:
  enabled: false
  save_prompts: false
  save_responses: false
  verbose_parsing: false
  mock_llm: true